{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9445a8db",
   "metadata": {
    "cell_id": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from itertools import combinations\n",
    "from scipy.special import factorial, comb\n",
    "from IPython.display import display, HTML\n",
    "from datetime import date, timedelta, datetime\n",
    "from typing import List\n",
    "from collections.abc import Callable\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27cc732f",
   "metadata": {
    "cell_id": 2
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setMaster('yarn')\n",
    "conf.setAppName('hive_sql_query')\n",
    "\n",
    "# set cluster name and queue that you have permission to access\n",
    "conf.set(\"spark.hadoop.yarn.cluster.name\", \"default\")\n",
    "conf.set(\"spark.yarn.queue\", \"root.mouse_tiktok_ug_data\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f90c6",
   "metadata": {
    "cell_id": 14
   },
   "source": [
    "## Shapley Value 分析算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf7a3cd",
   "metadata": {
    "cell_id": 19
   },
   "outputs": [],
   "source": [
    "class ShapAnalysis:\n",
    "    \n",
    "    def __init__(self, df, date_base, date_curr, dim, var, metric, weight, func):\n",
    "        self.df = df\n",
    "        self.date_base = date_base\n",
    "        self.date_curr = date_curr\n",
    "        self.dim = dim\n",
    "        self.var = var\n",
    "        self.metric = metric\n",
    "        self.weight = weight\n",
    "        self.func = func\n",
    "        # placeholders\n",
    "        self.metric_base = 0\n",
    "        self.metric_curr = 0\n",
    "        self.metric_delta = 0\n",
    "    \n",
    "    def process_data(self):\n",
    "        # generate df\n",
    "        df_base = custom_results(self.df, self.dim, self.date_base)\n",
    "        df_curr = custom_results(self.df, self.dim, self.date_curr)\n",
    "\n",
    "        # fill NA\n",
    "        df_base[self.dim] = df_base[self.dim].astype(str).fillna('_')\n",
    "        df_curr[self.dim] = df_curr[self.dim].astype(str).fillna('_')\n",
    "        df_base[self.var] = df_base[self.var].fillna(0)\n",
    "        df_curr[self.var] = df_curr[self.var].fillna(0)\n",
    "\n",
    "        # select required columns\n",
    "        df_base = df_base[self.dim + self.var]\n",
    "        df_curr = df_curr[self.dim + self.var]\n",
    "\n",
    "        # combine dimensions into a tuple\n",
    "        self.new_dim_col = '_dim'\n",
    "        df_base[self.new_dim_col] = df_base[self.dim].apply(tuple, axis=1)\n",
    "        df_curr[self.new_dim_col] = df_curr[self.dim].apply(tuple, axis=1)\n",
    "\n",
    "        # drop old dim cols\n",
    "        df_base, df_curr = df_base.drop(self.dim, axis=1), df_curr.drop(self.dim, axis=1)\n",
    "\n",
    "        # find the set of all dim values\n",
    "        self.dim_uniq = pd.concat([df_base[self.new_dim_col], df_curr[self.new_dim_col]]).unique()\n",
    "\n",
    "        # make sure both dataframes have records for all dim values\n",
    "        for d in self.dim_uniq:\n",
    "            new_row = dict()\n",
    "            new_row[self.new_dim_col] = d\n",
    "            for v in self.var:\n",
    "                new_row[v] = 0\n",
    "            # tuple in set\n",
    "            if d not in set(df_base[self.new_dim_col].values):\n",
    "                df_base = df_base.append(new_row, ignore_index=True)\n",
    "            if d not in set(df_curr[self.new_dim_col].values):\n",
    "                df_curr = df_curr.append(new_row, ignore_index=True)\n",
    "                \n",
    "        self.df_base = df_base\n",
    "        self.df_curr = df_curr\n",
    "        \n",
    "        # calc overall metrics\n",
    "        self.metric_base, self.metric_curr = \\\n",
    "            self.func(self.df_base), self.func(self.df_curr)\n",
    "        self.metric_delta = self.metric_curr - self.metric_base\n",
    "\n",
    "        \n",
    "    def analysis(self, sample_size=2):\n",
    "        # players: dim x variable\n",
    "        players = [(i, j) for i in range(len(self.dim_uniq)) for j in range(len(self.var))]\n",
    "\n",
    "        # sample\n",
    "        N = len(players)\n",
    "        sample_size = min(sample_size, factorial(N))\n",
    "        seq_list = list()\n",
    "        random.seed(666)\n",
    "        \n",
    "        for _ in range(sample_size):\n",
    "            seq = list(range(N))\n",
    "            random.shuffle(seq)\n",
    "            seq_list.append(seq)\n",
    "            \n",
    "        self.phi = dict()\n",
    "        \n",
    "        # reuse the same set of sequences for all players        \n",
    "        for seq in seq_list:\n",
    "            # make of copy of ctl\n",
    "            df_s = self.df_base.copy()\n",
    "            # current utility\n",
    "            v_current = self.func(df_s)\n",
    "\n",
    "            for i in range(N):\n",
    "                # select player p\n",
    "                p = players[seq[i]]\n",
    "                # select dim and variable\n",
    "                d, v = self.dim_uniq[p[0]], self.var[p[1]]\n",
    "                # update df_s\n",
    "                df_s.loc[lambda x: x[self.new_dim_col]==d, v] = \\\n",
    "                    self.df_curr.loc[lambda x: x[self.new_dim_col]==d, v].values\n",
    "                # calculate marginal utility\n",
    "                v_si = self.func(df_s)\n",
    "                phi_i = v_si - v_current\n",
    "                # update current utility\n",
    "                v_current = v_si\n",
    "\n",
    "                # add utility for player p\n",
    "                if p in self.phi:\n",
    "                    self.phi[p] += phi_i\n",
    "                else:\n",
    "                    self.phi[p] = phi_i\n",
    "        \n",
    "    \n",
    "    def process_results(self):\n",
    "        # standardize (because of sampling)\n",
    "        phi_std = {k:1.0*self.metric_delta*v/sum(self.phi.values()) for k, v in self.phi.items()}\n",
    "\n",
    "        # save contribution of each player\n",
    "        self.con = \\\n",
    "        [{'维度':self.dim_uniq[k[0]], \n",
    "          '变量':self.var[k[1]],\n",
    "          '贡献': v,\n",
    "         } for k, v in phi_std.items()]\n",
    "\n",
    "            \n",
    "    def display_contribution(self):\n",
    "        # contribution by dim combination\n",
    "        con_by_dim = pd.DataFrame(self.con)\n",
    "        \n",
    "        # contribution by var\n",
    "        con_by_var = con_by_dim.\\\n",
    "            groupby('变量')['贡献'].sum().reset_index()\n",
    "        con_by_var['贡献权重'] = con_by_var['贡献']/self.metric_delta\n",
    "        print(\"每个变量的整体贡献:\")\n",
    "        display(\n",
    "            con_by_var.style.hide_index().\\\n",
    "            background_gradient(\n",
    "                subset=pd.IndexSlice[:,['贡献权重']],\n",
    "                # cmap='plasma',\n",
    "                cmap='viridis',\n",
    "                    ).\\\n",
    "            format({\n",
    "                    '贡献':'{:.4f}',\n",
    "                    '贡献权重':'{:.2%}',\n",
    "                })\n",
    "        )\n",
    "        \n",
    "        # split dim tuple into separate dims\n",
    "        df_con_split = pd.concat(\n",
    "            [\n",
    "                pd.DataFrame(\n",
    "                    con_by_dim['维度'].tolist(), \n",
    "                    columns=self.dim\n",
    "                ), \n",
    "                con_by_dim\n",
    "            ], \n",
    "            axis=1,\n",
    "        )\n",
    "        print(\"每个变量贡献，按不同维度分解:\")\n",
    "        \n",
    "        for d in self.dim:\n",
    "            print(f\"\\n{'-'*10} 维度: {d}\")\n",
    "            # aggregate by dimension to provide metrics\n",
    "            df_base_d = custom_results(self.df, d, self.date_base)\n",
    "            df_curr_d = custom_results(self.df, d, self.date_curr)\n",
    "            df_con_by_var = list()\n",
    "            \n",
    "            for v in self.var:\n",
    "                # print(f\"{'-'*2} 指标: {v}. 累计贡献 {con_by_var[lambda x: x['变量']==v]['贡献'].values[0] :.4f}\")\n",
    "                df_con_grouped = \\\n",
    "                    df_con_split[lambda x: x['变量']==v].\\\n",
    "                    groupby(d)[['贡献']].sum().\\\n",
    "                    merge(df_base_d[[d, self.weight]], on=[d]).rename(columns={self.weight: '群体比重'}).\\\n",
    "                    merge(df_base_d[[d, v]], on=[d]).rename(columns={v: '基期'}).\\\n",
    "                    merge(df_curr_d[[d, v]], on=[d]).rename(columns={v: '现期'})\n",
    "                # df_con_grouped['贡献权重'] = df_con_grouped['贡献']/df_con_grouped['贡献'].sum()\n",
    "                df_con_grouped['群体比重'] = df_con_grouped['群体比重']/df_con_grouped['群体比重'].sum()\n",
    "                # df_con_grouped['重要度'] = np.abs(df_con_grouped['贡献权重'])/df_con_grouped['群体权重']\n",
    "                df_con_grouped['指标'] = v\n",
    "                # append to the list\n",
    "                df_con_by_var.append(df_con_grouped)\n",
    "            \n",
    "            # combine df for all vars and sort by contribution\n",
    "            df_con_all_vars = pd.concat(df_con_by_var, axis=0).\\\n",
    "                reset_index(drop=True).\\\n",
    "                sort_values(by='贡献',ascending=True if self.metric_delta<0 else False)\n",
    "            # add percentage metrics\n",
    "            df_con_all_vars['贡献比重'] = df_con_all_vars['贡献']/self.metric_delta\n",
    "            # add contribution per percent\n",
    "            df_con_all_vars['单位贡献'] = np.abs(df_con_all_vars['贡献'])/df_con_all_vars['群体比重']\n",
    "            df_con_all_vars['单位贡献'] = np.where(df_con_all_vars['群体比重'] >= 0.05, df_con_all_vars['单位贡献'], 0)\n",
    "            # sort columns manually\n",
    "            df_con_all_vars = df_con_all_vars[[d,'指标','基期','现期','贡献','贡献比重','群体比重','单位贡献']]\n",
    "            # print(df_con_all_vars)\n",
    "            \n",
    "            # display\n",
    "            display(\n",
    "                df_con_all_vars.style.hide_index().\\\n",
    "                    background_gradient(\n",
    "                        subset=pd.IndexSlice[:,['贡献比重','群体比重','单位贡献']],\n",
    "                        cmap='viridis',\n",
    "                ).\\\n",
    "                    format({\n",
    "                    '基期':'{:.4f}',\n",
    "                    '现期':'{:.4f}',\n",
    "                    '贡献':'{:.4f}',\n",
    "                    '贡献比重':'{:.2%}',\n",
    "                    '群体比重':'{:.2%}',\n",
    "                    '单位贡献':'{:.4f}'\n",
    "                })\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804618ae",
   "metadata": {
    "cell_id": 3
   },
   "source": [
    "## 数据源配置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe4a61",
   "metadata": {
    "cell_id": 6
   },
   "source": [
    "提前为分析场景配置的，一般不需要修改\n",
    "\n",
    "默认一次加载过去 DAYS_BACK 的数据，减少 DB 读取，后续都通过 Python 处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0a766e1",
   "metadata": {
    "cell_id": 7
   },
   "outputs": [],
   "source": [
    "# date range for raw data\n",
    "DAYS_BACK = 10\n",
    "\n",
    "data_date_start = date.today() - timedelta(days=DAYS_BACK+2)\n",
    "data_date_end = date.today() - timedelta(days=2)\n",
    "\n",
    "start_date = data_date_start.strftime('%Y%m%d')\n",
    "end_date = data_date_end.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4681c25e",
   "metadata": {
    "cell_id": 38
   },
   "outputs": [],
   "source": [
    "# start_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ef850",
   "metadata": {
    "cell_id": 9
   },
   "source": [
    "每日分维度的基础指标的 SQL。注意：维度如果包含 NULL 值，pandas 聚合结果就不准群。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c259449f",
   "metadata": {
    "cell_id": 11
   },
   "outputs": [],
   "source": [
    "# sql for raw data\n",
    "sql = \"\"\"\n",
    "select \n",
    "        from_unixtime(unix_timestamp(date, 'yyyyMMdd'), 'yyyy-MM-dd') as base_dt\n",
    "        , coalesce(region_group, 'unknown') as region_group\n",
    "        , coalesce(os, 'unknown') as os\n",
    "        , CASE WHEN app_id in ('1340','1339') THEN 'Lite' WHEN app_id in ('1180','1233') THEN 'TTmain' ELSE 'Others' END as app_name\n",
    "        , coalesce(media_type, 'unknown') as media_type\n",
    "        , case\n",
    "            when overall_score >= 11 then 'high++(>=11)'\n",
    "            when overall_score >= 9.5 then 'high+(9.5~11)'\n",
    "            when overall_score >= 8 then 'high(8~9.5)'\n",
    "            when overall_score >= 6.5 then 'mid(6.5~8)'\n",
    "            when overall_score >= 5 then 'low(5~6.5)'\n",
    "            when overall_score > 0 then 'extremely_low(<5)'\n",
    "            else 'other'\n",
    "        end as overall_score_range,\n",
    "       count(distinct device_id) as dnu,\n",
    "       count(distinct case when event in ('login_notify') then device_id else null end) as login_notify_uv,\n",
    "       count(distinct case when event in ('login_submit') and sequence_trans like '%login_notify%login_submit%' then device_id else null end) as login_submit_uv,\n",
    "       count(distinct case when event in ('login_success') and sequence_trans like '%login_notify%login_submit%login_success%' then device_id else null end) as login_success_uv,\n",
    "       count(distinct case when event in ('show_interest_selection','exit_interest_selection') and sequence_trans like '%login_notify%login_submit%login_success%interest_selection%' then device_id else null end) as interest_uv,\n",
    "       count(distinct case when event in ('welcomescreen_show','exit_welcomescreen') and sequence_trans like '%login_notify%login_submit%login_success%interest_selection%welcomescreen%' then device_id else null end) as welcomescreen_uv,\n",
    "       count(distinct case when event in ('video_play') and sequence_trans like '%login_notify%login_submit%login_success%interest_selection%welcomescreen%video_play%' then device_id else null end) as video_play_uv\n",
    "from\n",
    "(\n",
    "    select *,concat_ws(',',event_sequence_list) as sequence_trans\n",
    "    from ug_dw_int.dw_ug_new_user_onboarding_event_daily\n",
    "    where date between '{start_date}' and '{end_date}'\n",
    "    and app_id in ('1180','1233') -- For TT main only first\n",
    ") as tt \n",
    "left join tt_ug_da.media_source_mapping ms on tt.new_active_media_source = ms.media_source\n",
    "left join \n",
    "(\n",
    "    select \n",
    "        distinct \n",
    "        lower(country_code) as country,\n",
    "        region_group\n",
    "    from musically.mds_dim_geo_country\n",
    "    where date between '{start_date}' and '{end_date}'\n",
    ") as ci on tt.country = ci.country\n",
    "group by\n",
    "        from_unixtime(unix_timestamp(date, 'yyyyMMdd'), 'yyyy-MM-dd')\n",
    "        , coalesce(region_group, 'unknown') \n",
    "        , coalesce(os, 'unknown')\n",
    "        , CASE WHEN app_id in ('1340','1339') THEN 'Lite' WHEN app_id in ('1180','1233') THEN 'TTmain' ELSE 'Others' END \n",
    "        , coalesce(media_type, 'unknown') \n",
    "        , case\n",
    "            when overall_score >= 11 then 'high++(>=11)'\n",
    "            when overall_score >= 9.5 then 'high+(9.5~11)'\n",
    "            when overall_score >= 8 then 'high(8~9.5)'\n",
    "            when overall_score >= 6.5 then 'mid(6.5~8)'\n",
    "            when overall_score >= 5 then 'low(5~6.5)'\n",
    "            when overall_score > 0 then 'extremely_low(<5)'\n",
    "            else 'other'\n",
    "        end \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "867c401c",
   "metadata": {
    "cell_id": 12
   },
   "outputs": [],
   "source": [
    "sql_w_param = sql.format(**{'start_date': start_date, 'end_date': end_date})\n",
    "\n",
    "# run spark sql\n",
    "df_raw_spark = spark.sql(sql_w_param)\n",
    "# create pandas df\n",
    "df_raw = df_raw_spark.toPandas()\n",
    "# df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39ac39fc",
   "metadata": {
    "cell_id": 42
   },
   "outputs": [],
   "source": [
    "# df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9d6301c",
   "metadata": {
    "cell_id": 32
   },
   "outputs": [],
   "source": [
    "# df_raw.groupby('base_dt').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e9f11",
   "metadata": {
    "cell_id": 18
   },
   "source": [
    "后续按不同日期和维度在 Python 内聚合，提前写好聚合函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8fe7798",
   "metadata": {
    "cell_id": 23
   },
   "outputs": [],
   "source": [
    "def custom_aggregate(x):\n",
    "    s = {\n",
    "        '新增': x['dnu'].sum(),\n",
    "        '登录通知': x['login_notify_uv'].sum(),\n",
    "        '登录提交': x['login_submit_uv'].sum(),\n",
    "        '登录成功': x['login_success_uv'].sum(),\n",
    "        '兴趣选择': x['interest_uv'].sum(),\n",
    "        '欢迎页展示': x['welcomescreen_uv'].sum(),\n",
    "        '播放视频': x['video_play_uv'].sum(),\n",
    "    \n",
    "\n",
    "        '新增到播放视频': x['video_play_uv'].sum()/x['dnu'].sum(),\n",
    "        \n",
    "        '新增到登录通知': x['login_notify_uv'].sum()/x['dnu'].sum(),\n",
    "        '登录通知到登录提交': 0 if x['login_notify_uv'].sum() == 0 else x['login_submit_uv'].sum()/x['login_notify_uv'].sum(),\n",
    "        '登录提交到登录成功': 0 if x['login_submit_uv'].sum() == 0 else x['login_success_uv'].sum()/x['login_submit_uv'].sum(),\n",
    "        '登录成功到兴趣选择': 0 if x['login_success_uv'].sum() == 0 else x['interest_uv'].sum()/x['login_success_uv'].sum(),\n",
    "        '兴趣选择到欢迎页展示': 0 if x['interest_uv'].sum() == 0 else x['welcomescreen_uv'].sum()/x['interest_uv'].sum(),\n",
    "        '欢迎页展示到播放视频': 0 if x['welcomescreen_uv'].sum() == 0 else x['video_play_uv'].sum()/x['welcomescreen_uv'].sum(),\n",
    "\n",
    "\n",
    "    }\n",
    "    \n",
    "    return pd.Series(s, index=s.keys())\n",
    "\n",
    "\n",
    "def custom_results(df, dim_str_list, date_range_list):\n",
    "    temp = df[lambda x: x['base_dt'].between(*date_range_list)].\\\n",
    "        groupby(dim_str_list).apply(custom_aggregate).reset_index()\n",
    "    temp['总新增'] = temp['新增'].sum()\n",
    "    temp['总登录通知'] = temp['登录通知'].sum()\n",
    "    temp['总登录提交'] = temp['登录提交'].sum()\n",
    "    temp['总登录成功'] = temp['登录成功'].sum()\n",
    "    temp['总兴趣选择'] = temp['兴趣选择'].sum()\n",
    "    temp['总欢迎页展示'] = temp['欢迎页展示'].sum()\n",
    "    temp['总播放视频'] = temp['播放视频'].sum()\n",
    "    \n",
    "    temp['新增占比'] = temp['新增']/temp['总新增']\n",
    "    temp['登录通知占比'] = np.where(temp['总登录通知'] == 0, 0, temp['登录通知']/temp['总登录通知'])\n",
    "    temp['登录提交占比'] = np.where(temp['总登录提交'] == 0, 0, temp['登录提交']/temp['总登录提交'])\n",
    "    temp['登录成功占比'] = np.where(temp['总登录成功'] == 0, 0, temp['登录成功']/temp['总登录成功'])\n",
    "    temp['兴趣选择占比'] = np.where(temp['总兴趣选择'] == 0, 0, temp['兴趣选择']/temp['总兴趣选择'])\n",
    "    temp['欢迎页展示占比'] = np.where(temp['总欢迎页展示'] == 0, 0, temp['欢迎页展示']/temp['总欢迎页展示'])\n",
    "    temp['播放视频占比'] = np.where(temp['总播放视频'] == 0, 0, temp['播放视频']/temp['总播放视频'])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031119e3",
   "metadata": {
    "cell_id": 20
   },
   "source": [
    "## 分析过程\n",
    "\n",
    "每项配置对应一个分析任务。配置说明：\n",
    "\n",
    "- date_base 参照数据起止日期\n",
    "- date_curr 当前数据起止日期\n",
    "- dim 分析维度\n",
    "- var 用于计算指标的变量\n",
    "- metric 指标名称，可以随便取\n",
    "- weight 权重变量，通常选取用户数或用户占比\n",
    "- func 从 var 计算 metric 的 Python 函数\n",
    "\n",
    "配置可自行增改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c3ccfc5",
   "metadata": {
    "cell_id": 26
   },
   "outputs": [],
   "source": [
    "# common dates\n",
    "date_list = df_raw.base_dt.unique()\n",
    "latest_date = datetime.strptime(max(date_list), \"%Y-%m-%d\")\n",
    "\n",
    "# YESTERDAY = (date.today() - timedelta(days=4)).strftime('%Y-%m-%d')\n",
    "\n",
    "YESTERDAY = (latest_date - timedelta(days=0)).strftime('%Y-%m-%d')\n",
    "DOD = (latest_date - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "WOW = (latest_date - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "\n",
    "# compare dates\n",
    "wow = [WOW, WOW]\n",
    "dod = [DOD, DOD]\n",
    "ytd = [YESTERDAY, YESTERDAY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a1eea4b",
   "metadata": {
    "cell_id": 50
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 1, 25, 0, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4e468f0",
   "metadata": {
    "cell_id": 22
   },
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "# 新增入群率\n",
    "转化率_dod = {\n",
    "    'date_base': dod,\n",
    "    'date_curr': ytd,\n",
    "    'dim': ['region_group', 'media_type', 'os'],\n",
    "    'var': ['新增占比', '新增到登录通知', '登录通知到登录提交', '登录提交到登录成功', '登录成功到兴趣选择', '兴趣选择到欢迎页展示', '欢迎页展示到播放视频'],\n",
    "    'metric': '新增到播放视频',\n",
    "    'weight': '新增占比',\n",
    "    'func': lambda x: sum(x['新增占比']*x['新增到登录通知']*x['登录通知到登录提交']*x['登录提交到登录成功']*x['登录成功到兴趣选择']*x['兴趣选择到欢迎页展示']*x['欢迎页展示到播放视频']),\n",
    "}\n",
    "\n",
    "转化率_wow = {\n",
    "    'date_base': wow,\n",
    "    'date_curr': ytd,\n",
    "    'dim': ['region_group', 'media_type', 'os'],\n",
    "    'var': ['新增占比', '新增到登录通知', '登录通知到登录提交', '登录提交到登录成功', '登录成功到兴趣选择', '兴趣选择到欢迎页展示', '欢迎页展示到播放视频'],\n",
    "    'metric': '新增到播放视频',\n",
    "    'weight': '新增占比',\n",
    "    'func': lambda x: sum(x['新增占比']*x['新增到登录通知']*x['登录通知到登录提交']*x['登录提交到登录成功']*x['登录成功到兴趣选择']*x['兴趣选择到欢迎页展示']*x['欢迎页展示到播放视频']),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f408243a",
   "metadata": {
    "cell_id": 24
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- TTMAIN 的 新增到播放视频 指标 --------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'新增'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '新增'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e14664524c7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'-'*20} {(app_name.upper())} 的 {conf['metric']} 指标 {'-'*20}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShapAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'app_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mapp_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         print(\n\u001b[1;32m     11\u001b[0m             \u001b[0;34mf\"日期从 {conf['date_base']} 到 {conf['date_curr']}\\n指标从 {s.metric_base: .4f} 到 {s.metric_curr: .4f}，\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-81a863c4053b>\u001b[0m in \u001b[0;36mprocess_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# generate df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mdf_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mdf_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_curr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-77aa1cc28788>\u001b[0m in \u001b[0;36mcustom_results\u001b[0;34m(df, dim_str_list, date_range_list)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_dt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetween\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdate_range_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_str_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_aggregate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'总新增'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'新增'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'总登录通知'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'登录通知'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'总登录提交'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'登录提交'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '新增'"
     ]
    }
   ],
   "source": [
    "# 顺序分析\n",
    "for app_name in (['TTmain']):\n",
    "    \n",
    "    for conf in [\n",
    "        转化率_dod,\n",
    "    ]:\n",
    "        print(f\"{'-'*20} {(app_name.upper())} 的 {conf['metric']} 指标 {'-'*20}\")\n",
    "        s = ShapAnalysis(df_raw[lambda x: x['app_name'] == app_name], **conf)\n",
    "        s.process_data()\n",
    "        print(\n",
    "            f\"日期从 {conf['date_base']} 到 {conf['date_curr']}\\n指标从 {s.metric_base: .4f} 到 {s.metric_curr: .4f}，\" \n",
    "            f\"绝对变化: {s.metric_delta :.4f} 相对变化: {s.metric_delta/s.metric_base :.2%}\"\n",
    "        )\n",
    "        \n",
    "        # 相对变化到达一定值才分析\n",
    "        if abs(s.metric_curr/s.metric_base-1) >= 0.001:\n",
    "            s.analysis(sample_size=20)\n",
    "            s.process_results()\n",
    "            s.display_contribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab2d7d",
   "metadata": {
    "cell_id": 28
   },
   "outputs": [],
   "source": [
    "# 顺序分析\n",
    "for app_name in (['TTmain']):\n",
    "    \n",
    "    for conf in [\n",
    "        转化率_wow,\n",
    "    ]:\n",
    "        print(f\"{'-'*20} {(app_name.upper())} 的 {conf['metric']} 指标 {'-'*20}\")\n",
    "        s = ShapAnalysis(df_raw[lambda x: x['app_name'] == app_name], **conf)\n",
    "        s.process_data()\n",
    "        print(\n",
    "            f\"日期从 {conf['date_base']} 到 {conf['date_curr']}\\n指标从 {s.metric_base: .4f} 到 {s.metric_curr: .4f}，\" \n",
    "            f\"绝对变化: {s.metric_delta :.4f} 相对变化: {s.metric_delta/s.metric_base :.2%}\"\n",
    "        )\n",
    "        \n",
    "        # 相对变化到达一定值才分析\n",
    "        if abs(s.metric_curr/s.metric_base-1) >= 0.001:\n",
    "            s.analysis(sample_size=20)\n",
    "            s.process_results()\n",
    "            s.display_contribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9be95",
   "metadata": {
    "cell_id": 37
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "max_cell_id": 51,
  "serving": {
   "http": {
    "cache": {
     "period": "1440"
    },
    "enable": true,
    "mode": "cache"
   },
   "timer": {
    "enable": true,
    "expression": "5 8 * * *"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
